{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0adc4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pathlib\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import UNet, patchgan_discriminator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from generative.networks.nets import PatchDiscriminator\n",
    "from generative.losses import PatchAdversarialLoss\n",
    "from dataset import TrainDataset\n",
    "from preprocessing import split_dataset, get_patches\n",
    "\n",
    "# Parameters\n",
    "batch_size = 2\n",
    "patch_size = (32, 32, 32)\n",
    "stride = (16, 16, 16)\n",
    "target_shape = (192, 224, 192) \n",
    "num_epochs = 20\n",
    "lambda_adv = 0.01 # Weight for adversarial loss, from papers?\n",
    "\n",
    "# Define Generator and Discriminator\n",
    "G = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=2,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=None,\n",
    ")\n",
    "\n",
    "D = PatchDiscriminator(\n",
    "    spatial_dims=3,\n",
    "    num_channels=32,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4ac9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Loss Functions and Optimizers\n",
    "adv_loss = PatchAdversarialLoss(criterion=\"bce\") #andra parametrar?\n",
    "pix_loss = nn.L1Loss()\n",
    "\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=1e-4) #add betas?\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8a23a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data - make function of this?\n",
    "\n",
    "DATA_DIR = pathlib.Path.home()/\"data\"/\"bobsrepository\" #cluster?\n",
    "#DATA_DIR = pathlib.Path(\"/proj/synthetic_alzheimer/users/x_almle/bobsrepository\") #cluster?\n",
    "assert DATA_DIR.exists(), f\"DATA_DIR not found: {DATA_DIR}\"\n",
    "t1_files = sorted(DATA_DIR.rglob(\"*T1w.nii.gz\"))\n",
    "t2_files = sorted(DATA_DIR.rglob(\"*T2w.nii.gz\"))\n",
    "t2_LR_files = sorted(DATA_DIR.rglob(\"*T2w_LR.nii.gz\"))\n",
    "ref_img = nib.load(str(t1_files[0]))\n",
    "files = list(zip(t1_files, t2_files, t2_LR_files))\n",
    "train, val, test = split_dataset(files)\n",
    "train_t1, train_t2, train_t2_LR = get_patches(train, patch_size, stride, target_shape, ref_img)\n",
    "val_t1, val_t2, val_t2_LR = get_patches(val, patch_size, stride, target_shape, ref_img)\n",
    "test_t1, test_t2, test_t2_LR = get_patches(test, patch_size, stride, target_shape, ref_img)\n",
    "\n",
    "# Define dataloaders\n",
    "train_dataset = TrainDataset(train_t1, train_t2_LR, train_t2)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TrainDataset(val_t1, val_t2_LR, val_t2), batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fef31ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu (SLURM GPUs: 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PatchDiscriminator(\n",
       "  (initial_conv): Convolution(\n",
       "    (conv): Conv3d(3, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (adn): ADN(\n",
       "      (D): Dropout(p=0.0, inplace=False)\n",
       "      (A): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (0): Convolution(\n",
       "    (conv): Conv3d(16, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (adn): ADN(\n",
       "      (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (D): Dropout(p=0.0, inplace=False)\n",
       "      (A): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (1): Convolution(\n",
       "    (conv): Conv3d(32, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (adn): ADN(\n",
       "      (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (D): Dropout(p=0.0, inplace=False)\n",
       "      (A): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (2): Convolution(\n",
       "    (conv): Conv3d(64, 128, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (adn): ADN(\n",
       "      (N): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (D): Dropout(p=0.0, inplace=False)\n",
       "      (A): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Convolution(\n",
       "    (conv): Conv3d(128, 1, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Smart GPU/CPU detection\n",
    "import os\n",
    "slurm_gpus = int(os.environ.get('SLURM_GPUS_ON_NODE', '0'))\n",
    "has_gpu = torch.cuda.is_available() and slurm_gpus > 0 and torch.cuda.device_count() > 0\n",
    "\n",
    "device = torch.device(\"cuda\" if has_gpu else \"cpu\")\n",
    "print(f\"Using: {device} (SLURM GPUs: {slurm_gpus})\")\n",
    "\n",
    "G.to(device, dtype=torch.float32)\n",
    "D.to(device, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ab9dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m#Total loss\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     loss_G \u001b[38;5;241m=\u001b[39m g_pix \u001b[38;5;241m+\u001b[39m lambda_adv \u001b[38;5;241m*\u001b[39m g_adv\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mloss_G\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     g_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Generator Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_G\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Discriminator Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_D\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mri-sr-bob/.venv/lib/python3.9/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mri-sr-bob/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mri-sr-bob/.venv/lib/python3.9/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    G.train()\n",
    "    D.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input1, input2, target = batch\n",
    "\n",
    "        \n",
    "        inputs = torch.stack([input1, input2], dim=1).to(device, dtype=torch.float32, non_blocking=True)  # (B, 2, 32, 32, 32)\n",
    "        target = target.unsqueeze(1).to(device, dtype=torch.float32, non_blocking=True)  # (B, 1, 32, 32, 32)  \n",
    "        \n",
    "        #Generate fake image\n",
    "        fake_output = G(inputs)\n",
    "\n",
    "        real_pair = torch.cat([inputs, target], dim=1)  # (B, 3, 32, 32, 32)\n",
    "        fake_pair = torch.cat([inputs, fake_output.detach()], dim=1)  # (B, 3, 32, 32, 32)\n",
    "        \n",
    "        #DISCRIMINATOR TRAINING\n",
    "        d_optimizer.zero_grad()\n",
    "        pred_real = D(real_pair)\n",
    "        loss_real = adv_loss(pred_real[-1], target_is_real=True, for_discriminator=True)\n",
    "\n",
    "        pred_fake = D(fake_pair)\n",
    "        loss_fake = adv_loss(pred_fake[-1], target_is_real=False, for_discriminator=True)\n",
    "\n",
    "        #Total loss\n",
    "        loss_D = (loss_real + loss_fake) * 0.5\n",
    "        loss_D.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "\n",
    "        #GENERATOR TRAINING\n",
    "\n",
    "        fake_pair = torch.cat([inputs, fake_output], dim=1)  # (B, 3, 32, 32, 32)\n",
    "        pred_fake = D(fake_pair)\n",
    "        \n",
    "        g_optimizer.zero_grad()\n",
    "\n",
    "        g_adv = adv_loss(pred_fake[-1], target_is_real=True, for_discriminator=False) #förstår inte det här steget\n",
    "        g_pix = pix_loss(fake_output, target)\n",
    "        \n",
    "        #Total loss\n",
    "        loss_G = g_pix + lambda_adv * g_adv\n",
    "        loss_G.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Generator Loss: {loss_G.item():.4f}, Discriminator Loss: {loss_D.item():.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
