{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0adc4b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pathlib\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import UNet, patchgan_discriminator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from generative.networks.nets import PatchDiscriminator\n",
    "from generative.losses import PatchAdversarialLoss\n",
    "from dataset import TrainDataset\n",
    "from preprocessing import split_dataset, get_patches\n",
    "\n",
    "# Parameters\n",
    "batch_size = 2\n",
    "patch_size = (32, 32, 32)\n",
    "stride = (16, 16, 16)\n",
    "target_shape = (192, 224, 192) \n",
    "num_epochs = 50\n",
    "\n",
    "# Define Generator and Discriminator\n",
    "G = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=2,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=None,\n",
    ")\n",
    "\n",
    "D = PatchDiscriminator(\n",
    "    spatial_dims=3,\n",
    "    num_channels=4,\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4ac9aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Loss Functions and Optimizers\n",
    "d_loss = PatchAdversarialLoss() #andra parametrar?\n",
    "g_loss = nn.MSELoss()\n",
    "pixel_loss = nn.L1Loss()\n",
    "\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=1e-4) #add betas?\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8a23a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data - make function of this?\n",
    "\n",
    "DATA_DIR = pathlib.Path.home()/\"data\"/\"bobsrepository\" #cluster?\n",
    "#DATA_DIR = pathlib.Path(\"/proj/synthetic_alzheimer/users/x_almle/bobsrepository\") #cluster?\n",
    "assert DATA_DIR.exists(), f\"DATA_DIR not found: {DATA_DIR}\"\n",
    "t1_files = sorted(DATA_DIR.rglob(\"*T1w.nii.gz\"))\n",
    "t2_files = sorted(DATA_DIR.rglob(\"*T2w.nii.gz\"))\n",
    "t2_LR_files = sorted(DATA_DIR.rglob(\"*T2w_LR.nii.gz\"))\n",
    "ref_img = nib.load(str(t1_files[0]))\n",
    "files = list(zip(t1_files, t2_files, t2_LR_files))\n",
    "train, val, test = split_dataset(files)\n",
    "train_t1, train_t2, train_t2_LR = get_patches(train, patch_size, stride, target_shape, ref_img)\n",
    "val_t1, val_t2, val_t2_LR = get_patches(val, patch_size, stride, target_shape, ref_img)\n",
    "test_t1, test_t2, test_t2_LR = get_patches(test, patch_size, stride, target_shape, ref_img)\n",
    "\n",
    "# Define dataloaders\n",
    "train_dataset = TrainDataset(train_t1, train_t2_LR, train_t2)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TrainDataset(val_t1, val_t2_LR, val_t2), batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fef31ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu (SLURM GPUs: 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PatchDiscriminator(\n",
       "  (initial_conv): Convolution(\n",
       "    (conv): Conv3d(3, 16, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (adn): ADN(\n",
       "      (D): Dropout(p=0.0, inplace=False)\n",
       "      (A): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (0): Convolution(\n",
       "    (conv): Conv3d(16, 32, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (adn): ADN(\n",
       "      (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (D): Dropout(p=0.0, inplace=False)\n",
       "      (A): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (1): Convolution(\n",
       "    (conv): Conv3d(32, 64, kernel_size=(4, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "    (adn): ADN(\n",
       "      (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (D): Dropout(p=0.0, inplace=False)\n",
       "      (A): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (2): Convolution(\n",
       "    (conv): Conv3d(64, 128, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (adn): ADN(\n",
       "      (N): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (D): Dropout(p=0.0, inplace=False)\n",
       "      (A): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Convolution(\n",
       "    (conv): Conv3d(128, 1, kernel_size=(4, 4, 4), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Smart GPU/CPU detection\n",
    "import os\n",
    "slurm_gpus = int(os.environ.get('SLURM_GPUS_ON_NODE', '0'))\n",
    "has_gpu = torch.cuda.is_available() and slurm_gpus > 0 and torch.cuda.device_count() > 0\n",
    "\n",
    "device = torch.device(\"cuda\" if has_gpu else \"cpu\")\n",
    "print(f\"Using: {device} (SLURM GPUs: {slurm_gpus})\")\n",
    "\n",
    "G.to(device, dtype=torch.float32)\n",
    "D.to(device, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ab9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Generator Loss: 0.2474, Discriminator Loss: 0.2500\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    G.train()\n",
    "    D.train()\n",
    "    for batch in train_loader:\n",
    "        input1, input2, target = batch\n",
    "        inputs = torch.stack([input1, input2], dim=1).to(device, dtype=torch.float32, non_blocking=True)  # (B, 2, 32, 32, 32)\n",
    "        target = target.unsqueeze(1).to(device, dtype=torch.float32, non_blocking=True)  # (B, 1, 32, 32, 32)  \n",
    "        \n",
    "        # Train generator\n",
    "\n",
    "        g_optimizer.zero_grad()\n",
    "\n",
    "        #GAN loss\n",
    "        fake_output = G(inputs)\n",
    "        fake_pair = torch.cat([inputs, fake_output], dim=1)  # (B, 3, 32, 32, 32)\n",
    "        pred_fake = D(fake_pair)\n",
    "        loss_adv = d_loss(pred_fake[-1], target_is_real=True, for_discriminator=False) #förstår inte det här steget\n",
    "        \n",
    "        #Pixel loss\n",
    "        loss_pixel = g_loss(fake_output, target)\n",
    "\n",
    "        #Total loss\n",
    "        loss_G = loss_adv + loss_pixel\n",
    "        loss_G.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        #Train discriminator\n",
    "\n",
    "        d_optimizer.zero_grad()\n",
    "        pred_real = D(torch.cat([inputs, target], dim=1))\n",
    "        loss_real = d_loss(pred_real[-1], target_is_real=True, for_discriminator=True)\n",
    "\n",
    "        pred_fake = D(torch.cat([inputs, fake_output.detach()], dim=1))\n",
    "        loss_fake = d_loss(pred_fake[-1], target_is_real=False, for_discriminator=True)\n",
    "\n",
    "        #Total loss\n",
    "        loss_D = (loss_real + loss_fake) * 0.5\n",
    "        loss_D.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Generator Loss: {loss_G.item():.4f}, Discriminator Loss: {loss_D.item():.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
