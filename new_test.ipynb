{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d7f7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/al1612le/mri-sr-bob/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pathlib as p\n",
    "import nibabel as nib\n",
    "from monai.networks.nets import UNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import TrainDataset\n",
    "from preprocessing import reconstruct_from_patches, split_dataset, get_patches\n",
    "from file_structure import append_row\n",
    "import datetime\n",
    "from evaluations import calculate_metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ac8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = p.Path.home()/\"data\"/\"bobsrepository\"\n",
    "t1_files = sorted(DATA_DIR.rglob(\"*T1w.nii.gz\"))\n",
    "t2_files = sorted(DATA_DIR.rglob(\"*T2w.nii.gz\"))\n",
    "t2_LR_files = sorted(DATA_DIR.rglob(\"*T2w_LR.nii.gz\"))\n",
    "\n",
    "#t2_LR_files = create_and_save_LR_imgs(t2_files, scale_factor=2, output_dir=DATA_DIR/\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001d2389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files = list(zip(t1_files, t2_files, t2_LR_files))\n",
    "\n",
    "#SPLIT DATASET\n",
    "train, val, test = split_dataset(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9d5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#EXTRACT PATCHES\n",
    "\n",
    "patch_size = (64, 64, 64)\n",
    "stride = (32, 32, 32)\n",
    "ref_img = nib.load(str(t1_files[0]))\n",
    "target_shape = (192, 224, 192) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08326e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_t1, train_t2, train_t2_LR = get_patches(train, patch_size, stride, target_shape, ref_img)\n",
    "val_t1, val_t2, val_t2_LR = get_patches(val, patch_size, stride, target_shape, ref_img)\n",
    "test_t1, test_t2, test_t2_LR = get_patches(test, patch_size, stride, target_shape, ref_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802c317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 0.0088\n",
      "Epoch 2/2, Loss: 0.0021\n"
     ]
    }
   ],
   "source": [
    "#NETWORK TRAINING\n",
    "\n",
    "batch_size = 2\n",
    "shuffle = True\n",
    "\n",
    "\n",
    "# Flatten train data into a single list of patches\n",
    "#input_1 = [patch for img_patches in train_t1 for patch in img_patches]\n",
    "#input_2 = [patch for img_patches in train_t2_LR for patch in img_patches]\n",
    "#output = [patch for img_patches in train_t2 for patch in img_patches]\n",
    "\n",
    "train_dataset = TrainDataset(train_t1, train_t2_LR, train_t2)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle)\n",
    "\n",
    "net = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=2,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=None,\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "num_epochs = 5\n",
    "device = torch.device(\"cpu\") \n",
    "net.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        # Unpack your batch\n",
    "        input1, input2, target = batch\n",
    "        # Stack inputs along channel dimension\n",
    "        inputs = torch.stack([input1, input2], dim=1).float().to(device)  # (B, 2, 64, 64, 64)\n",
    "        target = target.unsqueeze(1).float().to(device)  # (B, 1, 64, 64, 64)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd59a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed validation image 1/11\n",
      "Processed validation image 2/11\n",
      "Processed validation image 3/11\n",
      "Processed validation image 4/11\n",
      "Processed validation image 5/11\n",
      "Processed validation image 6/11\n",
      "Processed validation image 7/11\n",
      "Processed validation image 8/11\n",
      "Processed validation image 9/11\n",
      "Processed validation image 10/11\n",
      "Processed validation image 11/11\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "generated_images = []\n",
    "real_images = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(val_t1)):\n",
    "        all_outputs = []\n",
    "        for j in range(len(val_t1[0])):\n",
    "            input1 = torch.tensor(val_t1[i][j]).float()\n",
    "            input2 = torch.tensor(val_t2_LR[i][j]).float()\n",
    "            inputs = torch.stack([input1, input2], dim=0).unsqueeze(0)  # (1, 2, 64, 64, 64)\n",
    "            output = net(inputs)\n",
    "            all_outputs.append(output.squeeze(0).squeeze(0).cpu().numpy())  # (64, 64, 64)\n",
    "        gen_reconstructed = reconstruct_from_patches(all_outputs, target_shape, stride)\n",
    "        real_reconstructed = reconstruct_from_patches(val_t2[i], target_shape, stride)\n",
    "        generated_images.append(gen_reconstructed)\n",
    "        real_images.append(real_reconstructed)\n",
    "        print(f\"Processed validation image {i+1}/{len(val_t1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bebb1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948765317488153 0.972458591309747\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "metrics = calculate_metrics(generated_images, real_images)\n",
    "\n",
    "all_interpolated = []\n",
    "for i in range(len(val_t2_LR)):\n",
    "    interpolated = reconstruct_from_patches(val_t2_LR[i], target_shape, stride)\n",
    "    all_interpolated.append(interpolated)\n",
    "interpolated_metrics = calculate_metrics(all_interpolated, real_images)\n",
    "print(np.mean(metrics['ssim']), np.mean(interpolated_metrics['ssim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e327864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE RESULTS\n",
    "\n",
    "\n",
    "row_dict = {\n",
    "    \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "    \"train_size\": len(train),\n",
    "    \"val_size\": len(val),\n",
    "    \"test_size\": len(test),\n",
    "    \"patch_size\": patch_size,\n",
    "    \"stride\": stride,\n",
    "    \"target_shape\": target_shape,\n",
    "    \"normalization\": \"min-max\",\n",
    "    \"model\": \"MONAI 3D U-Net\",\n",
    "    \"net spatial_dims\": 3,\n",
    "    \"net in_channels\": 2,\n",
    "    \"net out_channels\": 1,\n",
    "    \"net channels\": (16, 32, 64, 128, 256),\n",
    "    \"net strides\": (2, 2, 2, 2),\n",
    "    \"net num_res_units\": 2,\n",
    "    \"net norm\": None,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "    \"psnr\": metrics[\"psnr\"], \n",
    "    \"ssim\": metrics[\"ssim\"],\n",
    "    \"lpips\": None,\n",
    "    \"nrmse\": metrics[\"nrmse\"],\n",
    "    \"mse\": metrics[\"mse\"],\n",
    "    \"loss_fn\": \"MSELoss\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"notes\": \"Initial test run\",\n",
    "    \"masking\": \"None\",\n",
    "}\n",
    "\n",
    "append_row(DATA_DIR / \"results.csv\", row_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
